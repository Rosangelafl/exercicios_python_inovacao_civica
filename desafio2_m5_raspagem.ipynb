{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "desafio2_m5_raspagem.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPHqgIsZJxxFltsumYyt/xk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rosangelafl/exercicios_python_inovacao_civica/blob/main/desafio2_m5_raspagem.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kUtDQq0gW2KL"
      },
      "source": [
        "## Licitações do DOU - Diário oficial da união"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SZSRlWQVTjXh",
        "outputId": "c774d148-b3d8-4836-84d8-18202734ce13"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zhoJ38oaVvsO",
        "outputId": "bffddd4e-f7e4-45b5-973f-2938cecdb5f9"
      },
      "source": [
        "!pip install requests-html"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting requests-html\n",
            "  Downloading requests_html-0.10.0-py3-none-any.whl (13 kB)\n",
            "Collecting pyquery\n",
            "  Downloading pyquery-1.4.3-py3-none-any.whl (22 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from requests-html) (2.23.0)\n",
            "Collecting parse\n",
            "  Downloading parse-1.19.0.tar.gz (30 kB)\n",
            "Collecting w3lib\n",
            "  Downloading w3lib-1.22.0-py2.py3-none-any.whl (20 kB)\n",
            "Collecting fake-useragent\n",
            "  Downloading fake-useragent-0.1.11.tar.gz (13 kB)\n",
            "Collecting pyppeteer>=0.0.14\n",
            "  Downloading pyppeteer-0.2.6-py3-none-any.whl (83 kB)\n",
            "\u001b[K     |████████████████████████████████| 83 kB 2.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: bs4 in /usr/local/lib/python3.7/dist-packages (from requests-html) (0.0.1)\n",
            "Requirement already satisfied: importlib-metadata>=1.4 in /usr/local/lib/python3.7/dist-packages (from pyppeteer>=0.0.14->requests-html) (4.8.1)\n",
            "Collecting urllib3<2.0.0,>=1.25.8\n",
            "  Downloading urllib3-1.26.7-py2.py3-none-any.whl (138 kB)\n",
            "\u001b[K     |████████████████████████████████| 138 kB 60.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm<5.0.0,>=4.42.1 in /usr/local/lib/python3.7/dist-packages (from pyppeteer>=0.0.14->requests-html) (4.62.2)\n",
            "Collecting pyee<9.0.0,>=8.1.0\n",
            "  Downloading pyee-8.2.2-py2.py3-none-any.whl (12 kB)\n",
            "Requirement already satisfied: appdirs<2.0.0,>=1.4.3 in /usr/local/lib/python3.7/dist-packages (from pyppeteer>=0.0.14->requests-html) (1.4.4)\n",
            "Collecting websockets<10.0,>=9.1\n",
            "  Downloading websockets-9.1-cp37-cp37m-manylinux2010_x86_64.whl (103 kB)\n",
            "\u001b[K     |████████████████████████████████| 103 kB 55.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=1.4->pyppeteer>=0.0.14->requests-html) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=1.4->pyppeteer>=0.0.14->requests-html) (3.5.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.7/dist-packages (from bs4->requests-html) (4.6.3)\n",
            "Requirement already satisfied: lxml>=2.1 in /usr/local/lib/python3.7/dist-packages (from pyquery->requests-html) (4.2.6)\n",
            "Collecting cssselect>0.7.9\n",
            "  Downloading cssselect-1.1.0-py2.py3-none-any.whl (16 kB)\n",
            "Collecting urllib3<2.0.0,>=1.25.8\n",
            "  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n",
            "\u001b[K     |████████████████████████████████| 127 kB 46.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->requests-html) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->requests-html) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->requests-html) (2021.5.30)\n",
            "Requirement already satisfied: six>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from w3lib->requests-html) (1.15.0)\n",
            "Building wheels for collected packages: fake-useragent, parse\n",
            "  Building wheel for fake-useragent (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fake-useragent: filename=fake_useragent-0.1.11-py3-none-any.whl size=13502 sha256=b1e2454f85446e18fe5001136d3768dc5b9d1ac82cae6f4487552234a824c362\n",
            "  Stored in directory: /root/.cache/pip/wheels/ed/f7/62/50ab6c9a0b5567267ab76a9daa9d06315704209b2c5d032031\n",
            "  Building wheel for parse (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for parse: filename=parse-1.19.0-py3-none-any.whl size=24591 sha256=0a583de4824ca73d99d1443bf83f5123bda236ce180e4a5540eeebca032603a5\n",
            "  Stored in directory: /root/.cache/pip/wheels/9c/aa/cc/f2228050ccb40f22144b073f15a2c84f11204f29fc0dce028e\n",
            "Successfully built fake-useragent parse\n",
            "Installing collected packages: websockets, urllib3, pyee, cssselect, w3lib, pyquery, pyppeteer, parse, fake-useragent, requests-html\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Successfully installed cssselect-1.1.0 fake-useragent-0.1.11 parse-1.19.0 pyee-8.2.2 pyppeteer-0.2.6 pyquery-1.4.3 requests-html-0.10.0 urllib3-1.25.11 w3lib-1.22.0 websockets-9.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "faJcC-u6VcdF",
        "outputId": "c74c915c-7237-4782-d31e-d13688e35f82"
      },
      "source": [
        "!pip install folium==0.2.1"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting folium==0.2.1\n",
            "  Downloading folium-0.2.1.tar.gz (69 kB)\n",
            "\u001b[?25l\r\u001b[K     |████▊                           | 10 kB 26.3 MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 20 kB 30.4 MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 30 kB 33.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 40 kB 23.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 51 kB 19.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 61 kB 15.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 69 kB 5.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: Jinja2 in /usr/local/lib/python3.7/dist-packages (from folium==0.2.1) (2.11.3)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2->folium==0.2.1) (2.0.1)\n",
            "Building wheels for collected packages: folium\n",
            "  Building wheel for folium (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for folium: filename=folium-0.2.1-py3-none-any.whl size=79809 sha256=fe950c92e23ff1f46a7e7acbc61a88020739bf99cb9d71e893d35648d202dece\n",
            "  Stored in directory: /root/.cache/pip/wheels/9a/f0/3a/3f79a6914ff5affaf50cabad60c9f4d565283283c97f0bdccf\n",
            "Successfully built folium\n",
            "Installing collected packages: folium\n",
            "  Attempting uninstall: folium\n",
            "    Found existing installation: folium 0.8.3\n",
            "    Uninstalling folium-0.8.3:\n",
            "      Successfully uninstalled folium-0.8.3\n",
            "Successfully installed folium-0.2.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OxDiv4ZMUD-L"
      },
      "source": [
        "import datetime\n",
        "import pandas as pd\n",
        "from requests_html import HTMLSession"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hxpkYyWaVZn2"
      },
      "source": [
        "url = \"http://comprasnet.gov.br/ConsultaLicitacoes/ConsLicitacaoDia.asp\"\n",
        "session = HTMLSession()\n",
        "response = session.get(url)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NlIDYOKbWfGL"
      },
      "source": [
        "licitacoes = []\n",
        "rows = response.html.xpath(\"//form\")\n",
        "for row in rows:\n",
        "    descricao = row.xpath(\"./form/table/tr[2]//text()\")\n",
        "    descricao = '\\n'.join(descricao).strip()\n",
        "    item = {\n",
        "        \"data\": datetime.date.today(),\n",
        "        \"descricao\": descricao,\n",
        "    }\n",
        "    licitacoes.append(item)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ejizZYApg9MK"
      },
      "source": [
        "#### Adicionando ao DataFrame"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_adPNxiIbszU"
      },
      "source": [
        "df_licitacoes = pd.DataFrame(licitacoes)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MPOJzZ7ShQH_"
      },
      "source": [
        "Replicando para todas as páginas.\n",
        "\n",
        "Recomenda-se transformar a extração de conteúdo da página em uma função que pode ser chamada para cada página."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5sHfyyphhJNq"
      },
      "source": [
        "def extract_licitacoes(response):\n",
        "    \"\"\"Se desejar, preencha esta função\"\"\"\n",
        "    licitacoes = []\n",
        "    rows = response.html.xpath(\"//form\")\n",
        "    for row in rows:\n",
        "        descricao = row.xpath(\"./form/table/tr[2]//text()\")\n",
        "        descricao = '\\n'.join(descricao).strip()\n",
        "        item = {\n",
        "            \"data\": datetime.date.today(),\n",
        "            \"descricao\": descricao,\n",
        "        }\n",
        "        licitacoes.append(item)\n",
        "    return licitacoes"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yahPxx1GhiHU"
      },
      "source": [
        "page = 1\n",
        "next_page_button = response.html.xpath(\"//input[@name='proxima']\")\n",
        "while next_page_button:\n",
        "    page += 1\n",
        "    next_page_url = f\"{url}?pagina={page}\"\n",
        "    response = session.get(next_page_url)\n",
        "    licitacoes = extract_licitacoes(response)\n",
        "    df_licitacoes = df_licitacoes.append(pd.DataFrame(licitacoes))\n",
        "    next_page_button = response.html.xpath(\"//input[@name='proxima']\")"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5-OzGWQShks8"
      },
      "source": [
        "Salvando em JSON"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fza-ol_shJfy"
      },
      "source": [
        "df_licitacoes.to_json('licitacoes.json', orient=\"records\", date_format=\"iso\")"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a0YaoPfnhwHJ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}